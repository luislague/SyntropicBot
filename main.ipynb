{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai-whisper in /usr/local/lib/python3.11/dist-packages (20240930)\n",
      "Requirement already satisfied: yt_dlp in /usr/local/lib/python3.11/dist-packages (2024.11.4)\n",
      "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (1.0.1)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.46.2)\n",
      "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (0.60.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (1.26.3)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (2.1.1+cu121)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (4.66.1)\n",
      "Requirement already satisfied: more-itertools in /usr/lib/python3/dist-packages (from openai-whisper) (8.10.0)\n",
      "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (0.8.0)\n",
      "Requirement already satisfied: triton>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (2.1.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.26.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->openai-whisper) (0.43.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->transformers) (2020.6.20)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->openai-whisper) (2.1.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.11/dist-packages (from sympy->torch->openai-whisper) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: langchain-community in /usr/local/lib/python3.11/dist-packages (0.3.5)\n",
      "Requirement already satisfied: langchain-openai in /usr/local/lib/python3.11/dist-packages (0.2.6)\n",
      "Requirement already satisfied: langchain-pinecone in /usr/local/lib/python3.11/dist-packages (0.2.0)\n",
      "Requirement already satisfied: pinecone-client in /usr/local/lib/python3.11/dist-packages (5.0.1)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/lib/python3/dist-packages (from langchain-community) (5.4.1)\n",
      "Requirement already satisfied: SQLAlchemy<2.0.36,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.21)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.9.5)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.0)\n",
      "Requirement already satisfied: langchain<0.4.0,>=0.3.6 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.7)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.15)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.1.141)\n",
      "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (1.26.3)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.6.1)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.31.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.0.0)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.54.0 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (1.54.3)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (0.8.0)\n",
      "Requirement already satisfied: certifi>=2019.11.17 in /usr/lib/python3/dist-packages (from pinecone-client) (2020.6.20)\n",
      "Requirement already satisfied: pinecone-plugin-inference<2.0.0,>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from pinecone-client) (1.1.0)\n",
      "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in /usr/local/lib/python3.11/dist-packages (from pinecone-client) (0.0.7)\n",
      "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.11/dist-packages (from pinecone-client) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.11/dist-packages (from pinecone-client) (4.12.2)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from pinecone-client) (2.0.7)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.23.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from langchain<0.4.0,>=0.3.6->langchain-community) (0.3.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<0.4.0,>=0.3.6->langchain-community) (2.9.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-community) (23.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (3.10.11)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.54.0->langchain-openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.54.0->langchain-openai) (1.7.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.54.0->langchain-openai) (0.7.0)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.54.0->langchain-openai) (1.3.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2->langchain-community) (3.3)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/lib/python3/dist-packages (from SQLAlchemy<2.0.36,>=1.4->langchain-community) (1.1.2)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2023.12.25)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.0.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain-community) (2.4)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.6->langchain-community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.6->langchain-community) (2.23.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.5.2)\n",
      "Requirement already satisfied: giskard[llm] in /usr/local/lib/python3.11/dist-packages (2.15.3)\n",
      "Requirement already satisfied: cloudpickle>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from giskard[llm]) (2.2.1)\n",
      "Requirement already satisfied: zstandard>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from giskard[llm]) (0.23.0)\n",
      "Requirement already satisfied: mlflow-skinny>=2 in /usr/local/lib/python3.11/dist-packages (from giskard[llm]) (2.17.2)\n",
      "Requirement already satisfied: numpy<2,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from giskard[llm]) (1.26.3)\n",
      "Requirement already satisfied: scipy<1.12.0,>=1.7.3 in /usr/local/lib/python3.11/dist-packages (from giskard[llm]) (1.11.2)\n",
      "Requirement already satisfied: mixpanel>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from giskard[llm]) (4.10.1)\n",
      "Requirement already satisfied: requests>=2.19 in /usr/local/lib/python3.11/dist-packages (from giskard[llm]) (2.31.0)\n",
      "Requirement already satisfied: pydantic<3,>1 in /usr/local/lib/python3.11/dist-packages (from giskard[llm]) (2.9.2)\n",
      "Requirement already satisfied: pandas>=2.0 in /usr/local/lib/python3.11/dist-packages (from giskard[llm]) (2.2.0)\n",
      "Requirement already satisfied: xxhash>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from giskard[llm]) (3.4.1)\n",
      "Requirement already satisfied: langdetect>=1.0.9 in /usr/local/lib/python3.11/dist-packages (from giskard[llm]) (1.0.9)\n",
      "Requirement already satisfied: chardet in /usr/lib/python3/dist-packages (from giskard[llm]) (4.0.0)\n",
      "Requirement already satisfied: jinja2>=3 in /usr/local/lib/python3.11/dist-packages (from giskard[llm]) (3.1.3)\n",
      "Requirement already satisfied: requests-toolbelt>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from giskard[llm]) (1.0.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from giskard[llm]) (69.0.3)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from giskard[llm]) (4.12.2)\n",
      "Requirement already satisfied: pyyaml in /usr/lib/python3/dist-packages (from giskard[llm]) (5.4.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from giskard[llm]) (23.2)\n",
      "Requirement already satisfied: markdown in /usr/local/lib/python3.11/dist-packages (from giskard[llm]) (3.5.2)\n",
      "Requirement already satisfied: colorama in /usr/local/lib/python3.11/dist-packages (from giskard[llm]) (0.4.3)\n",
      "Requirement already satisfied: num2words>=0.5.13 in /usr/local/lib/python3.11/dist-packages (from giskard[llm]) (0.5.13)\n",
      "Requirement already satisfied: griffe<0.49.0,>=0.36.9 in /usr/local/lib/python3.11/dist-packages (from giskard[llm]) (0.48.0)\n",
      "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (from giskard[llm]) (1.54.3)\n",
      "Requirement already satisfied: evaluate>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from giskard[llm]) (0.4.3)\n",
      "Requirement already satisfied: bert-score>=0.3.13 in /usr/local/lib/python3.11/dist-packages (from giskard[llm]) (0.3.13)\n",
      "Requirement already satisfied: tenacity>=4.11.0 in /usr/local/lib/python3.11/dist-packages (from giskard[llm]) (9.0.0)\n",
      "Requirement already satisfied: faiss-cpu<1.8.0.post1,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from giskard[llm]) (1.8.0)\n",
      "Requirement already satisfied: bokeh<3.5,>=3.3.4 in /usr/local/lib/python3.11/dist-packages (from giskard[llm]) (3.4.3)\n",
      "Requirement already satisfied: umap-learn>=0.5.5 in /usr/local/lib/python3.11/dist-packages (from giskard[llm]) (0.5.7)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.2.0)\n",
      "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from bert-score>=0.3.13->giskard[llm]) (2.1.1+cu121)\n",
      "Requirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from bert-score>=0.3.13->giskard[llm]) (4.46.2)\n",
      "Requirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.11/dist-packages (from bert-score>=0.3.13->giskard[llm]) (4.66.1)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from bert-score>=0.3.13->giskard[llm]) (3.7.3)\n",
      "Requirement already satisfied: contourpy>=1.2 in /usr/local/lib/python3.11/dist-packages (from bokeh<3.5,>=3.3.4->giskard[llm]) (1.2.0)\n",
      "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from bokeh<3.5,>=3.3.4->giskard[llm]) (9.5.0)\n",
      "Requirement already satisfied: tornado>=6.2 in /usr/local/lib/python3.11/dist-packages (from bokeh<3.5,>=3.3.4->giskard[llm]) (6.4)\n",
      "Requirement already satisfied: xyzservices>=2021.09.1 in /usr/local/lib/python3.11/dist-packages (from bokeh<3.5,>=3.3.4->giskard[llm]) (2024.9.0)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate>=0.4.1->giskard[llm]) (2.14.5)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate>=0.4.1->giskard[llm]) (0.3.7)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate>=0.4.1->giskard[llm]) (0.70.15)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate>=0.4.1->giskard[llm]) (2023.6.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate>=0.4.1->giskard[llm]) (0.26.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2>=3->giskard[llm]) (2.1.4)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from langdetect>=1.0.9->giskard[llm]) (1.16.0)\n",
      "Requirement already satisfied: urllib3 in /usr/local/lib/python3.11/dist-packages (from mixpanel>=4.4.0->giskard[llm]) (2.0.7)\n",
      "Requirement already satisfied: cachetools<6,>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny>=2->giskard[llm]) (5.3.2)\n",
      "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny>=2->giskard[llm]) (8.1.7)\n",
      "Requirement already satisfied: databricks-sdk<1,>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny>=2->giskard[llm]) (0.36.0)\n",
      "Requirement already satisfied: gitpython<4,>=3.1.9 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny>=2->giskard[llm]) (3.1.41)\n",
      "Requirement already satisfied: importlib-metadata!=4.7.0,<9,>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny>=2->giskard[llm]) (8.5.0)\n",
      "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny>=2->giskard[llm]) (1.28.0)\n",
      "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny>=2->giskard[llm]) (1.28.0)\n",
      "Requirement already satisfied: protobuf<6,>=3.12.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny>=2->giskard[llm]) (4.23.4)\n",
      "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny>=2->giskard[llm]) (0.5.1)\n",
      "Requirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.11/dist-packages (from num2words>=0.5.13->giskard[llm]) (0.6.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0->giskard[llm]) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas>=2.0->giskard[llm]) (2022.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0->giskard[llm]) (2023.4)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>1->giskard[llm]) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>1->giskard[llm]) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19->giskard[llm]) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.19->giskard[llm]) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.19->giskard[llm]) (2020.6.20)\n",
      "Requirement already satisfied: numba>=0.51.2 in /usr/local/lib/python3.11/dist-packages (from umap-learn>=0.5.5->giskard[llm]) (0.60.0)\n",
      "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.11/dist-packages (from umap-learn>=0.5.5->giskard[llm]) (0.5.13)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai->giskard[llm]) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai->giskard[llm]) (1.7.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai->giskard[llm]) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai->giskard[llm]) (0.7.0)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai->giskard[llm]) (1.3.0)\n",
      "Requirement already satisfied: google-auth~=2.0 in /usr/local/lib/python3.11/dist-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny>=2->giskard[llm]) (2.26.2)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate>=0.4.1->giskard[llm]) (15.0.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate>=0.4.1->giskard[llm]) (3.9.5)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython<4,>=3.1.9->mlflow-skinny>=2->giskard[llm]) (4.0.11)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai->giskard[llm]) (1.0.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai->giskard[llm]) (0.14.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate>=0.4.1->giskard[llm]) (3.13.1)\n",
      "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny>=2->giskard[llm]) (3.20.2)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.2->umap-learn>=0.5.5->giskard[llm]) (0.43.0)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny>=2->giskard[llm]) (1.2.14)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.49b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny>=2->giskard[llm]) (0.49b0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score>=0.3.13->giskard[llm]) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score>=0.3.13->giskard[llm]) (3.2.1)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert-score>=0.3.13->giskard[llm]) (2.1.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert-score>=0.3.13->giskard[llm]) (2023.12.25)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert-score>=0.3.13->giskard[llm]) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert-score>=0.3.13->giskard[llm]) (0.20.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score>=0.3.13->giskard[llm]) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score>=0.3.13->giskard[llm]) (4.47.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert-score>=0.3.13->giskard[llm]) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib->bert-score>=0.3.13->giskard[llm]) (2.4.7)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate>=0.4.1->giskard[llm]) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate>=0.4.1->giskard[llm]) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate>=0.4.1->giskard[llm]) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate>=0.4.1->giskard[llm]) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate>=0.4.1->giskard[llm]) (1.9.4)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny>=2->giskard[llm]) (1.14.1)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny>=2->giskard[llm]) (5.0.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny>=2->giskard[llm]) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/lib/python3/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny>=2->giskard[llm]) (4.8)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.11/dist-packages (from sympy->torch>=1.0.0->bert-score>=0.3.13->giskard[llm]) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/lib/python3/dist-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny>=2->giskard[llm]) (0.4.8)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.5.0)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (22.1.0)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.2.0)\n",
      "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.115.4)\n",
      "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.4.0)\n",
      "Requirement already satisfied: gradio-client==1.4.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.4.2)\n",
      "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.27.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.25.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.26.2)\n",
      "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.3)\n",
      "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.1.4)\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.26.3)\n",
      "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.11)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (23.2)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.0)\n",
      "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (9.5.0)\n",
      "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.9.2)\n",
      "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: python-multipart==0.0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.12)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/lib/python3/dist-packages (from gradio) (5.4.1)\n",
      "Requirement already satisfied: ruff>=0.2.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.7.2)\n",
      "Requirement already satisfied: safehttpx<1.0,>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.1)\n",
      "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.41.2)\n",
      "Requirement already satisfied: tomlkit==0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.12.0)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.0)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.12.2)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.32.0)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.4.2->gradio) (2023.6.0)\n",
      "Requirement already satisfied: websockets<13.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.4.2->gradio) (12.0)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/lib/python3/dist-packages (from anyio<5.0,>=3.0->gradio) (3.3)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.0)\n",
      "Requirement already satisfied: certifi in /usr/lib/python3/dist-packages (from httpx>=0.24.1->gradio) (2020.6.20)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.1->gradio) (3.13.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.1->gradio) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.1->gradio) (4.66.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas<3.0,>=1.0->gradio) (2022.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2023.4)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (2.23.4)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.17.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (2.0.7)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Core libraries for AI model handling, speech processing, and environment setup\n",
    "!pip install openai-whisper yt_dlp python-dotenv transformers --upgrade\n",
    "\n",
    "# LangChain extensions and vector database integration\n",
    "!pip install -U langchain-community langchain-openai langchain-pinecone pinecone-client\n",
    "\n",
    "# Utilities for model evaluation, machine learning, and simple UI interfaces\n",
    "!pip install giskard[llm] scikit-learn --upgrade\n",
    "!pip install gradio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import cuda\n",
    "\n",
    "# Set device to GPU if available; otherwise, use CPU\n",
    "device = f'cuda:{cuda.current_device()}' if cuda.is_available() else 'cpu'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "# Load environment variables from \"environment.env\" file\n",
    "load_dotenv(find_dotenv(\"environment.env\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yt_dlp\n",
    "import logging\n",
    "\n",
    "def download_audio_from_youtube(playlist_url, output_path=\"/notebooks/Files/%(title)s.%(ext)s\"):\n",
    "    \"\"\"\n",
    "    Downloads audio from a YouTube playlist or video and saves it as an mp3 file.\n",
    "\n",
    "    Args:\n",
    "        playlist_url (str): URL of the YouTube playlist or video to download.\n",
    "        output_path (str, optional): Path format for saving the audio file. \n",
    "                                     Defaults to '/notebooks/Files/%(title)s.%(ext)s'.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Configure yt-dlp options for audio download\n",
    "    ydl_opts = {\n",
    "        'format': 'bestaudio/best',  # Best available audio quality\n",
    "        'outtmpl': output_path,      # Output file naming format\n",
    "        'postprocessors': [{         # Convert audio to mp3\n",
    "            'key': 'FFmpegExtractAudio',\n",
    "            'preferredcodec': 'mp3',\n",
    "            'preferredquality': '192',\n",
    "        }],\n",
    "        'ignoreerrors': True,        # Continue to next video on error\n",
    "    }\n",
    "\n",
    "    # Initialize logging for better error tracking\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "    \n",
    "    try:\n",
    "        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "            ydl.download([playlist_url])\n",
    "        logging.info(\"Download completed successfully.\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error downloading audio: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "import os\n",
    "import logging\n",
    "from typing import Optional\n",
    "\n",
    "def transcribe_audio_files(audio_dir: str, transcription_dir: str, model_type: str = \"medium\") -> Optional[None]:\n",
    "    \"\"\"\n",
    "    Transcribes audio files in the specified directory using the Whisper model.\n",
    "\n",
    "    Args:\n",
    "        audio_dir (str): Directory containing audio files to transcribe.\n",
    "        transcription_dir (str): Directory to save transcription files.\n",
    "        model_type (str, optional): Type of Whisper model to use. Defaults to \"medium\".\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Initialize logging\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "    # Load Whisper model\n",
    "    try:\n",
    "        model = whisper.load_model(model_type)\n",
    "        logging.info(f\"Loaded Whisper model: {model_type}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error loading model '{model_type}': {e}\")\n",
    "        return\n",
    "\n",
    "    # Check if audio directory exists\n",
    "    if not os.path.isdir(audio_dir):\n",
    "        logging.error(f\"Audio directory '{audio_dir}' does not exist.\")\n",
    "        return\n",
    "\n",
    "    # Ensure transcription directory exists\n",
    "    os.makedirs(transcription_dir, exist_ok=True)\n",
    "    \n",
    "    # Define supported audio file extensions\n",
    "    supported_extensions = (\".mp3\", \".wav\", \".m4a\")\n",
    "    \n",
    "    # Get list of supported audio files in the audio directory\n",
    "    audio_files = [f for f in os.listdir(audio_dir) if f.endswith(supported_extensions)]\n",
    "    if not audio_files:\n",
    "        logging.info(\"No audio files found in the specified directory.\")\n",
    "        return\n",
    "    \n",
    "    # Transcribe each audio file and save it as a .txt file\n",
    "    for audio_file in audio_files:\n",
    "        audio_path = os.path.join(audio_dir, audio_file)\n",
    "        \n",
    "        try:\n",
    "            # Transcribe audio file\n",
    "            transcription = model.transcribe(audio_path)\n",
    "            \n",
    "            # Save transcription to a .txt file\n",
    "            transcription_file = os.path.join(\n",
    "                transcription_dir, os.path.splitext(audio_file)[0] + \".txt\"\n",
    "            )\n",
    "            with open(transcription_file, \"w\") as f:\n",
    "                f.write(transcription['text'])\n",
    "            \n",
    "            logging.info(f\"Transcribed and saved: {transcription_file}\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error transcribing file '{audio_file}': {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_243/2338940585.py:11: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embedding_model = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
      "INFO:root:Processing file: /notebooks/Files/TranscriptionMedium/COMPLETE guide to Food Forest Design + Installation (2024 ⧸ Syntropic Agroforestry).txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Processing file: /notebooks/Files/TranscriptionMedium/(Audiolivro) AGRICULTURA SINTRÓPICA  SEGUNDO ERNST GÖTSCH.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Processing file: /notebooks/Files/TranscriptionMedium/Agricultura Sintrópica em larga escala - Ernst Götsch.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Processing file: /notebooks/Files/TranscriptionMedium/charla sintropia parteII.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Processing file: /notebooks/Files/TranscriptionMedium/3 big negatives - Syntropic style agroforestry.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Processing file: /notebooks/Files/TranscriptionMedium/TALLER LIBERADO Bosques Sintrópicos de Alimento - Agricultura Sintrópica & Permacultura.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "WARNING:root:Skipping .ipynb_checkpoints, not a file.\n",
      "INFO:root:Processing file: /notebooks/Files/TranscriptionMedium/charla_sintropia_parteI.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:root:Vectorization complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Define the path to the transcription folder\n",
    "transcription_folder = \"/notebooks/Files/TranscriptionMedium/\"\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=300)\n",
    "\n",
    "# Retrieve the list of files in the transcription folder\n",
    "transcription_files = os.listdir(transcription_folder)\n",
    "if transcription_files:\n",
    "    vectorized_segments = []\n",
    "    global_counter = 0  # Initialize global counter\n",
    "\n",
    "    for transcription_file in transcription_files:\n",
    "        transcription_path = os.path.join(transcription_folder, transcription_file)\n",
    "        if os.path.isfile(transcription_path):\n",
    "            logging.info(f\"Processing file: {transcription_path}\")\n",
    "\n",
    "            # Read file content\n",
    "            with open(transcription_path, 'r', encoding='utf-8') as file:\n",
    "                transcription_text = file.read()\n",
    "\n",
    "            # Split text into segments\n",
    "            segments = text_splitter.split_text(transcription_text)\n",
    "\n",
    "            # Vectorize segments and store them with metadata\n",
    "            if segments:\n",
    "                embeddings = embedding_model.embed_documents(segments)\n",
    "\n",
    "                for segment, vector in zip(segments, embeddings):\n",
    "                    vectorized_segments.append({\n",
    "                        \"id\": f\"segment_{global_counter}\",\n",
    "                        \"text\": segment,\n",
    "                        \"embedding\": vector\n",
    "                    })\n",
    "                    global_counter += 1\n",
    "            else:\n",
    "                logging.warning(f\"No segments to vectorize in file {transcription_file}.\")\n",
    "        else:\n",
    "            logging.warning(f\"Skipping {transcription_file}, not a file.\")\n",
    "\n",
    "    logging.info(\"Vectorization complete.\")\n",
    "else:\n",
    "    logging.warning(\"No files found in the transcription folder.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segment ID: segment_700\n",
      "Text: biodiversidad que puede haber en un espacio y no tiene que haber como una receta de estructura de lí...\n",
      "Embedding Length: 1536\n",
      "Embedding Sample: [-0.0022095004820747066, -0.0033531620800466683, 0.012248685053575965, -0.006686022724285242, -0.014969110979474438]\n",
      "--------------------------------------------------\n",
      "Segment ID: segment_701\n",
      "Text: come la morera también en su momento va a dar fruta ahí a la derecha y acá tenemos como un rincón sú...\n",
      "Embedding Length: 1536\n",
      "Embedding Sample: [0.0026737159638039265, -0.019193522002558683, 0.003713586944349937, -0.009017760569600314, -0.011446899358969724]\n",
      "--------------------------------------------------\n",
      "Segment ID: segment_702\n",
      "Text: fotos más de cerca las hojas están como enceradas parece que alguien de mañana temprano va le pone c...\n",
      "Embedding Length: 1536\n",
      "Embedding Sample: [-0.0053752645462626925, -0.004242046632097743, 0.0027778886042679482, 0.0006873686047187222, -0.012281543273886784]\n",
      "--------------------------------------------------\n",
      "Segment ID: segment_703\n",
      "Text: correctamente con las plantas alrededor siguiente por favor gracias bueno acá ya vamos acercándonos ...\n",
      "Embedding Length: 1536\n",
      "Embedding Sample: [-0.008760883946140078, 0.0024092431550377185, 0.008671906313877143, -0.0027685762947360676, -0.0002457582000692972]\n",
      "--------------------------------------------------\n",
      "Segment ID: segment_704\n",
      "Text: es algo fijo entonces vos tenés que generar tu propia receta según vos donde estás no es lo mismo si...\n",
      "Embedding Length: 1536\n",
      "Embedding Sample: [0.003250813304124421, -0.012394590149383931, -0.009890772279461436, -0.004371306339011989, -0.003048502103753031]\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Print 5 segments to check structure\n",
    "for segment in vectorized_segments[700:705]:\n",
    "    print(\"Segment ID:\", segment[\"id\"])\n",
    "    print(\"Text:\", segment[\"text\"][:100] + \"...\")  # Show first 100 characters of text\n",
    "    print(\"Embedding Length:\", len(segment[\"embedding\"]))\n",
    "    print(\"Embedding Sample:\", segment[\"embedding\"][:5])  # Show first 5 values in the embedding\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: 0.82 - Segment: What's ripening YouTube? So I had a recent comment on a video and the question that came up was what...\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "from typing import List, Tuple\n",
    "\n",
    "# Define a function to search for similar segments\n",
    "def search_similar_segment(query_text: str, embedding_model, vectorized_segments: List[dict], top_k: int = 1) -> List[Tuple[str, float]]:\n",
    "    \"\"\"\n",
    "    Search for segments similar to the query text based on cosine similarity.\n",
    "\n",
    "    Args:\n",
    "        query_text (str): The text to search for similarities.\n",
    "        embedding_model: The embedding model used to generate embeddings.\n",
    "        vectorized_segments (List[dict]): List of segments with embeddings.\n",
    "        top_k (int): Number of top similar segments to return.\n",
    "\n",
    "    Returns:\n",
    "        List[Tuple[str, float]]: List of tuples containing text of similar segments and their similarity scores.\n",
    "    \"\"\"\n",
    "    if not vectorized_segments:\n",
    "        print(\"No vectorized segments available.\")\n",
    "        return []\n",
    "\n",
    "    # Generate embedding for the query text\n",
    "    query_embedding = embedding_model.embed_documents([query_text])[0]\n",
    "\n",
    "    # Extract embeddings from vectorized_segments\n",
    "    segment_embeddings = [segment[\"embedding\"] for segment in vectorized_segments]\n",
    "\n",
    "    # Calculate cosine similarity with each stored embedding\n",
    "    similarities = cosine_similarity([query_embedding], segment_embeddings).flatten()\n",
    "\n",
    "    # Find the top_k most similar segments\n",
    "    top_k_indices = np.argsort(similarities)[-top_k:][::-1]\n",
    "    similar_segments = [(vectorized_segments[i][\"text\"], similarities[i]) for i in top_k_indices]\n",
    "\n",
    "    return similar_segments\n",
    "\n",
    "# Example usage\n",
    "query_text = \"negatives for syntropic agriculture\"\n",
    "similar_segments = search_similar_segment(query_text, embedding_model, vectorized_segments)\n",
    "\n",
    "# Print the results\n",
    "for segment, similarity in similar_segments:\n",
    "    print(f\"Similarity: {similarity:.2f} - Segment: {segment[:100]}...\")  # Truncate for display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total segments vectorized: 874\n"
     ]
    }
   ],
   "source": [
    "# Display the total number of vectorized segments\n",
    "print(f\"Total segments vectorized: {len(vectorized_segments)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique embedding lengths: {1536}\n",
      "All embeddings have consistent dimensions.\n"
     ]
    }
   ],
   "source": [
    "# Check for consistency in embedding dimensions\n",
    "embedding_lengths = {len(segment[\"embedding\"]) for segment in vectorized_segments}\n",
    "print(\"Unique embedding lengths:\", embedding_lengths)\n",
    "\n",
    "# Confirm consistency\n",
    "if len(embedding_lengths) == 1:\n",
    "    print(\"All embeddings have consistent dimensions.\")\n",
    "else:\n",
    "    print(\"Warning: Inconsistent embedding dimensions found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All segments are valid.\n"
     ]
    }
   ],
   "source": [
    "# Check if each segment has text and a non-empty embedding\n",
    "valid_segments = all(segment[\"text\"] and segment[\"embedding\"] for segment in vectorized_segments)\n",
    "\n",
    "if valid_segments:\n",
    "    print(\"All segments are valid.\")\n",
    "else:\n",
    "    print(\"Warning: Some segments are missing text or embeddings.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import ServerlessSpec\n",
    "import os\n",
    "\n",
    "# Securely fetch Pinecone API key and ensure it is set\n",
    "api_key = os.getenv(\"PINECONE_API_KEY\")\n",
    "if api_key:\n",
    "    os.environ[\"PINECONE_API_KEY\"] = api_key\n",
    "else:\n",
    "    raise ValueError(\"PINECONE_API_KEY not found. Please set it in your environment variables.\")\n",
    "\n",
    "# Define the serverless specification for Pinecone\n",
    "spec = ServerlessSpec(\n",
    "    cloud=\"aws\", \n",
    "    region=\"us-east-1\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pinecone_plugin_interface.logging:Discovering subpackages in _NamespacePath(['/usr/local/lib/python3.11/dist-packages/pinecone_plugins'])\n",
      "INFO:pinecone_plugin_interface.logging:Looking for plugins in pinecone_plugins.inference\n",
      "INFO:pinecone_plugin_interface.logging:Installing plugin inference into Pinecone\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {'': {'vector_count': 874}},\n",
       " 'total_vector_count': 874}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "from pinecone import Pinecone\n",
    "\n",
    "\n",
    "# Initialize Pinecone client with the updated API\n",
    "pc = Pinecone(api_key=os.environ[\"PINECONE_API_KEY\"])\n",
    "\n",
    "index_name = \"agricultura-sintropica\"\n",
    "\n",
    "# Check if the index exists; create if it doesn’t\n",
    "if index_name not in [index_info[\"name\"] for index_info in pc.list_indexes()]:\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=1536,  # OpenAI embedding dimension\n",
    "        metric=\"dotproduct\",\n",
    "        spec=spec\n",
    "    )\n",
    "    # Wait for the index to be ready\n",
    "    while not pc.describe_index(index_name).status[\"ready\"]:\n",
    "        time.sleep(1)\n",
    "\n",
    "# Connect to the index for upsertion\n",
    "index = pc.Index(index_name)\n",
    "time.sleep(1)\n",
    "# view index stats\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1519638bd16c4f54845b4993091d20c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upserting Batches:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All segments have been upserted into Pinecone.\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Define batch size for upsertion\n",
    "batch_size = 50\n",
    "\n",
    "# Upsert embeddings to Pinecone in batches\n",
    "for i in tqdm(range(0, len(vectorized_segments), batch_size), desc=\"Upserting Batches\"):\n",
    "    batch = vectorized_segments[i:i + batch_size]\n",
    "    ids = [segment[\"id\"] for segment in batch]\n",
    "    embeddings = [segment[\"embedding\"] for segment in batch]\n",
    "    metadatas = [{\"text\": segment[\"text\"]} for segment in batch]\n",
    "\n",
    "    # Attempt upsertion of each batch to Pinecone\n",
    "    try:\n",
    "        index.upsert(vectors=list(zip(ids, embeddings, metadatas)))\n",
    "    except Exception as e:\n",
    "        print(f\"Error upserting batch {i // batch_size + 1}: {e}\")\n",
    "\n",
    "print(\"All segments have been upserted into Pinecone.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index statistics: {'dimension': 1536,\n",
      " 'index_fullness': 0.0,\n",
      " 'namespaces': {'': {'vector_count': 874}},\n",
      " 'total_vector_count': 874}\n"
     ]
    }
   ],
   "source": [
    "# View and display index stats\n",
    "index_stats = index.describe_index_stats()\n",
    "print(\"Index statistics:\", index_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LANGCHAIN_TRACING_V2 set to: true\n",
      "LANGCHAIN_ENDPOINT set to: https://api.smith.langchain.com\n",
      "LANGCHAIN_PROJECT set to: pr-drab-platinum-76\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Set environment variables for LangChain tracing and endpoint configuration\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"pr-drab-platinum-76\"\n",
    "\n",
    "# Verify environment variables are set\n",
    "required_vars = [\"LANGCHAIN_TRACING_V2\", \"LANGCHAIN_ENDPOINT\", \"LANGCHAIN_PROJECT\"]\n",
    "for var in required_vars:\n",
    "    if var in os.environ:\n",
    "        print(f\"{var} set to: {os.environ[var]}\")\n",
    "    else:\n",
    "        print(f\"Warning: {var} is not set.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "import os\n",
    "\n",
    "# Define the model name\n",
    "model_name = 'text-embedding-ada-002'\n",
    "\n",
    "# Retrieve the OpenAI API key securely\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not api_key:\n",
    "    raise ValueError(\"OpenAI API key is not set. Please set OPENAI_API_KEY in environment variables.\")\n",
    "\n",
    "# Initialize the OpenAIEmbeddings model\n",
    "embed = OpenAIEmbeddings(\n",
    "    model=model_name,\n",
    "    openai_api_key=api_key\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PineconeVectorStore initialized successfully.\n"
     ]
    }
   ],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "# Initialize PineconeVectorStore with the specified index, embedding model, and text key\n",
    "try:\n",
    "    vector_store = PineconeVectorStore(index=index, embedding=embedding_model, text_key=\"text\")\n",
    "    print(\"PineconeVectorStore initialized successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing PineconeVectorStore: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, I'm the Syntropic Bot 🌴🤖🌴. \n",
      "\n",
      "Ask me all your questions about Syntropic Agroforestry! \n",
      "\n",
      "If you don't know where to start, here are some suggestions:\n",
      "\n",
      "🪱 What do I need to consider about the soil when starting a Syntropic Agroforest?\n",
      "🌳 If I want to start a Syntropic aAgroforest, what are the main things to consider at the beginning?\n",
      "🤔 What are the challengues of Syntropic Agroforestry?\n",
      "\n",
      "Type \"exit\", \"quit\", or \"stop\" to end our conversation. ❌\n",
      "\n",
      "Thank you for your questions. Now it's time to plant, prune, and regenerate!\n",
      "Goodbye, and happy planting!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Pinecone\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "from langchain.prompts import PromptTemplate\n",
    "import pinecone\n",
    "\n",
    "\n",
    "\n",
    "# Initialize the OpenAI embedding model and Pinecone vector store\n",
    "embedding_model = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-ada-002\", \n",
    "    openai_api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "\n",
    "vector_store = Pinecone(\n",
    "    index, \n",
    "    embedding_model, \"text\")\n",
    "\n",
    "conversational_memory = ConversationBufferWindowMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True,\n",
    "    k=4,\n",
    "    output_key=\"answer\"\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model_name=\"gpt-4o-mini\",\n",
    "    openai_api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "\n",
    "retriever = vector_store.as_retriever(search_type='similarity', search_kwargs={'k': 8})\n",
    "\n",
    "custom_template = \"\"\"\n",
    "You are a helpful and informative AI assistant that is good at remembering previous turns in the conversation to give helpful and relevant answers.\n",
    "You answer in the same language as the question is asked.\n",
    "Do not provide information that is not part of the context.\n",
    "\n",
    "Instructions:\n",
    "1. You analize the chat history and enrich your context if the question is related.\n",
    "2. If the question is provided in a particular language, you answer in the same language.\n",
    "3. If you do not find the answer to the question in the context, you look for synonyms of the question in the context.\n",
    "4. If explaining technical concepts, provide clear examples\n",
    "5. If  you do not find the answer in the context, you answer saying \"I can't find the answer. Please ask another question!\".\n",
    "\"\"\"\"\"\"\n",
    "\n",
    "Current conversation: \n",
    "{chat_history}\n",
    "\n",
    "Context: \n",
    "{context}\n",
    "\n",
    "User's question: \n",
    "{question}\n",
    "\n",
    "Syntropic Bot Answer:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Prompt template\n",
    "response_template = PromptTemplate(\n",
    "    template=custom_template,\n",
    "    input_variables=[\"question\", \"chat_history\", \"context\"],\n",
    ")\n",
    "\n",
    "qa_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    memory=conversational_memory,\n",
    "    combine_docs_chain_kwargs={\"prompt\": response_template},\n",
    "    return_source_documents=True,\n",
    "    #get_chat_history=lambda h: h,\n",
    ")\n",
    "\n",
    "def chat():\n",
    "    print(\"\"\"Hello, I'm the Syntropic Bot 🌴🤖🌴. \n",
    "\n",
    "Ask me all your questions about Syntropic Agroforestry! \n",
    "\n",
    "If you don't know where to start, here are some suggestions:\n",
    "\n",
    "🪱 What do I need to consider about the soil when starting a Syntropic Agroforest?\n",
    "🌳 If I want to start a Syntropic aAgroforest, what are the main things to consider at the beginning?\n",
    "🤔 What are the challengues of Syntropic Agroforestry?\n",
    "\n",
    "Type \"exit\", \"quit\", or \"stop\" to end our conversation. ❌\n",
    "\"\"\")\n",
    "\n",
    "    while True:\n",
    "        question = input(\"You: \")\n",
    "        exit_phrases = [\"exit\", \"quit\", \"stop\"]\n",
    "        if question.lower() in exit_phrases:\n",
    "            print(\"Thank you for your questions. Now it's time to plant, prune, and regenerate!\")\n",
    "            break\n",
    "        try:\n",
    "            # Get the response from the chain\n",
    "            response = qa_chain.invoke({\"question\": question})\n",
    "            # Extract and print the answer\n",
    "            if 'answer' in response:\n",
    "                print(f\"Syntropic Bot: {response['answer']}\")\n",
    "            else:\n",
    "                print(\"Syntropic Bot: Sorry, I could not understand your question.\")\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}. Please ask your question again\")\n",
    "    print(\"Goodbye, and happy planting!\")\n",
    "\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    chat()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
